---
tags:
- card_type/scenario
- compiled-code
- python-models
- seeds
citations:
- cleaned_docs/python-models/rank_4.md
guid: d189eda0a5
source: llm
uuid: 79548f3f-8e07-5540-ad25-24bf1b039e53
---

<front>

A dbt Python model running on Snowflake is failing with an "Out of Memory" error when processing a 50GB dataset. The code uses `df = dbt.ref('source').to_pandas()`. How should you fix this?

</front>

---

<back>

Remove the `.to_pandas()` conversion and use the native **Snowpark DataFrame** methods instead. This keeps the data processing inside Snowflake's engine rather than pulling it all into the memory of the Python execution environment.

</back>
