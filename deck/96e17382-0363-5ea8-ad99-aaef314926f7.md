---
tags:
- card_type/scenario
- debugging/compiled-code
- development/materializations
- development/sql-performance
citations:
- cleaned_docs/snapshots/rank_5.md
guid: 69fa706f1c
source: llm
uuid: 96e17382-0363-5ea8-ad99-aaef314926f7
---

<front>

A large incremental model on Snowflake is performing slowly because the merge operation scans the entire 10TB destination table. The table is clustered by `event_date`. How would you optimize this?

</front>

---

<back>

Use `incremental_predicates` to limit the destination scan to a recent time window.
This pushes a filter into the merge join, allowing the database to leverage clustering/partition pruning on the destination table.
```yaml
{{ config(
  materialized='incremental',
  unique_key='event_id',
  incremental_strategy='merge',
  incremental_predicates=["DBT_INTERNAL_DEST.event_date >= dateadd(day, -7, current_date)"]
) }}
```

</back>
